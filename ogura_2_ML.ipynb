{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import joblib\n",
    "import json\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のサイズ\n",
    "h, w = 64, 64\n",
    "\n",
    "# 画像作成する文字（ひらがな、Noneは白い画像を意味）\n",
    "text_options = list(\"あいうえおかきくけこさしすせそたちつてとなにぬねのはひふへほまみむめもやゆよらりるれろわゐゑをん\") + [None]\n",
    "\n",
    "font_paths = [\n",
    "    \"C:/Windows/Fonts/msmincho.ttc\",  # 明朝体1\n",
    "    \"C:/Windows/Fonts/yumin.ttf\",  # 明朝体2\n",
    "    \"C:/Windows/Fonts/BIZ-UDMinchoM.ttc\",    # 明朝体3\n",
    "    \"C:/Windows/Fonts/HGRMB.ttc\",   #明朝体4 \n",
    "    \"C:/Windows/Fonts/HGRME.ttc\",   #明朝体5\n",
    "    \"C:/Windows/Fonts/msgothic.ttc\", # ゴシック体1\n",
    "    \"C:/Windows/Fonts/UDDigiKyokashoN-R.ttc\",    #教科書体1\n",
    "    \"C:/Windows/Fonts/UDDigiKyokashoN-B.ttc\",    #教科書体2\n",
    "    \"C:/Windows/Fonts/HGRGY.ttc\",       #行書体1\n",
    "    \"C:/Windows/Fonts/HGRSKP.ttf\",      #楷書体1\n",
    "]\n",
    "\n",
    "# 結果を保存するリスト\n",
    "imgs = []\n",
    "labels = []  # テキストかNoneを保存するリスト\n",
    "\n",
    "for text in text_options:\n",
    "    for font_path in font_paths:\n",
    "        for i in range(500):\n",
    "            # ランダムに25〜60の範囲でフォントサイズを選択\n",
    "            font_size = random.randint(30, 70)\n",
    "            font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "            # 画像を白背景で生成\n",
    "            img = Image.new(\"L\", (w, h), \"white\")\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            # テキストがNoneでない場合にのみ描画\n",
    "            if text is not None:\n",
    "                \n",
    "                offset_x = random.randint(-20, 20) \n",
    "                offset_y = random.randint(-20, 20)\n",
    "                position = (w // 2 + offset_x, h // 2 + offset_y)\n",
    "\n",
    "                # テキストを描画\n",
    "                draw.text(position, text, fill=\"black\", font=font, anchor=\"mm\")\n",
    "\n",
    "            # 二値化: ピクセル値が255のときのみ255を保持、それ以外は0に設定\n",
    "            binary = np.where(np.array(img) == 255, 255, 0).astype(np.uint8)\n",
    "            \n",
    "            # 画像をndarrayに変換してリストに保存\n",
    "            imgs.append(np.array(binary))\n",
    "            labels.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = shuffle(imgs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgs, labels):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "\n",
    "        # None を特別な処理として扱う\n",
    "        self.label_map = {label: idx for idx, label in enumerate(sorted(label for label in set(labels) if label is not None))}\n",
    "        self.label_map[None] = len(self.label_map)  # None を最後のラベルとして追加\n",
    "\n",
    "        # transforms: そのままか180度回転をランダムに適用した後、左右に最大15度回転を追加\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),  # 画像をTensorに変換\n",
    "            transforms.RandomChoice([  # ランダムでどちらかを適用\n",
    "                transforms.RandomRotation(degrees=[0, 0]),  # そのまま\n",
    "                transforms.RandomRotation(degrees=[180, 180])  # 180度回転\n",
    "            ]),\n",
    "            transforms.RandomRotation(degrees=[-30, 30])  # -30度から30度の間でランダム回転\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 画像を取得して前処理\n",
    "        img = self.imgs[idx].astype(np.float32) / 255.0  # 正規化\n",
    "        img = self.transform(img)  # transforms を適用\n",
    "\n",
    "        # ラベルを取得してインデックスに変換\n",
    "        label = self.labels[idx]\n",
    "        label_idx = self.label_map[label]\n",
    "\n",
    "        return img, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット作成\n",
    "dataset = ImageDataset(imgs, labels)\n",
    "n_classes = len(dataset.label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの分割\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(64, 32, 3, 1, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 16, 3, 1, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.fc3 = nn.Linear(1024, out_channels)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.reshape((x.size(0), -1))  # 出力を平坦化\n",
    "        x = self.fc3(x)  # 全結合層に入力\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# デバイス設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# モデル、損失関数、オプティマイザの設定\n",
    "model = CNN(1, n_classes).to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習プロセス\n",
    "epochs = 30\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(train_loader)\n",
    "    for X, y_true in pbar:\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = (torch.argmax(y_pred, dim=1) == y_true).float().mean()\n",
    "        losses.append(loss.item())\n",
    "        accuracies.append(acc.item())\n",
    "        pbar.set_description(f\"Epoch {epoch+1} Loss: {loss.item():.4f} Acc: {acc.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価\n",
    "model.eval()\n",
    "n_correct = 0\n",
    "n_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y_true in tqdm(test_loader):\n",
    "        X, y_true = X.to(device), y_true.to(device)\n",
    "        y_pred = model(X)\n",
    "        n_correct += (torch.argmax(y_pred, dim=1) == y_true).sum().item()\n",
    "        n_total += y_true.size(0)\n",
    "\n",
    "accuracy = n_correct / n_total\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {\n",
    "    \"model\": model.state_dict(),\n",
    "    \"optim\": optimizer.state_dict(),\n",
    "}\n",
    "torch.save(ckpt, \"ckpt.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
